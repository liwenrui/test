1. KafKa简介
初识KafKa

笔者是怎么了解到KafKa的呢?其实这个也源于InfoQ大会的功劳(InfoQ大会是一个技术架构分享峰会),在之间有很多大家耳熟能详的公司来分享一些技术,大家在谈论大数据技术的时候使用到了本文开篇提的Hadoop,spark,storm此类技术,但是他们都要有一个共同点,就是大部分使用了KafKa作为了数据传输的通道,并且还有很多不需要使用到大数据的公司也在使用KafKa,为什么都要使用KafKa呢?KafKa能支撑大数据处理吗,KafKa还能做什么,笔者带着这些疑问,开始对KafKa进行了了解!
kafKa是什么

KafKa是一款由Apache软件基金会开源,由Scala编写的一个分布式发布订阅消息系统,Kafka最初是由LinkedIn开发，并于2011年初开源(知道这个就够了),KafKa它最初的目的是为了解决,统一,高效低延时,高通量(同时能传输的数据量)并且高可用一个消息平台.

说的更简单易懂一点就是帮助程序之间互相传递消息,并且提供一些保证,所有的大数据处理也好,微服务也好他们都有一个共同的需求就是一个稳定的数据通道,KafKa刚好就是一个稳定高效通道最佳选择!
KafKa中的几个角色

    broker:对于KafKa集群来说,每一个KafKa实例都被称为一个broker
    Topic(主题):在KafKa中每一条消息都所属一个Topic下,Topic之间是完全物理隔离的
    Partitine(分区):一个Topic下面可以拥有一个到多个Partitine,Partitine也是物理层面的隔离
    peoduker(生产者):向kafka的Topic发布消息
    consumer(消费者):向Topic注册，并且接收发布到这些Topic的消息

KafKa的特性

笔者也是总结了一些关于KafKa的一些特性如下:

    kafka接收到的消息最终会以文件的形式存在本地保证了,只要消息接受成功理论上就不会丢失
    KafKa通过append来实现消息的追加,保证消息都是有序的有先来后到的顺序
    KafKa集群有良好的容灾机制,比如有N台服务器,可以承受N-1台服务器故障是保证提交的消息不会丢失
    KafKa会更具Topic以及partition来进行消息在本地的物理划分
    KafKa依赖zookeeper实现了offset,你不用关心到你获取了那些消息KafKa会知道并且在你下次获取时接着给你
    你可以获取任意一个offset的记录
    消息可以在KafKa内保存很长的时间也可以很短,KafKa基于文件系统能存储消息的容量取决于硬盘空间
    KafKa的性能不会受到消息的数量影响

2. KafKa的使用场景
消息队列(MQ)

KafKa可以代替传统的消息队列软件(阿里的队列软件RocketMQ就是基于KafKa实现的),在队列软件的选择上KafKa已经成了不二之选,使用KafKa来实现队列有如下优点

    KafKa的append来实现消息的追加,保证消息都是有序的有先来后到的顺序,
    稳定性强队列在使用中最怕丢失数据,KafKa能做到理论上的写成功不丢失
    分布式容灾好
    容量大相对于内存队列,KafKa的容量受硬盘影响
    数据量不会影响到KafKa的速度

就以上几点和笔者之前使用的Redis来承载队列服务要优秀的多,在后续文章的比较中会一一说明
分布式日志系统(Log)

在很多时候我们需要对一些庞大的数据进行存留,一些业务型公司可能永不上应为基本可以依靠数据库解决日志的问题,但是服务型公司比如jpush,云监控此类服务,日志存储这块会遇到巨大的问题,日志不能丢,日志存文件不好找,定位一条消息成本高(遍历当天日志文件),实时显示给用户难,这几类问题KafKa都能游刃有余

    KafKa的集群备份机制能做到n/2的可用,当n/2以下的机器宕机时存储的日志不会丢失
    KafKa可以对消息进行分组分片,并且通过offset可以做到获取中间莫一条消息(通过算法很容易的到莫个时段的日志)
    KafKa非常容易做到实时日志查询,可以从日志尾部获取需要显示给用户查询的资料即可

数据通道(Messaging)

kafka特有的offset机制能够保证消息至少被获取一次,当程序在获取途中死亡这条消息会被认定为未被消费,下次会继续消费这条消息,此特性使得kafka可以作为一个保障数据传输的通道来使用,但是kafka并没有提供JMS中的"事务性""消息传输担保(消息确认机制)""消息分组"等企业级特性;所以kafka只能使用作为"常规"的消息系统
